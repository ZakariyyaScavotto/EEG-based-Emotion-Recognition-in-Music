{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set up Rivanna GPU to train Deep_iSith and LSTM models\n",
    "### 1. Use  PyTorch 1.4.0 Py3.7 Kernal/ Container on Rivanna\n",
    "Try to use V100 GPU, since it is much faster than the others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pip install the necessary packages and download the [SITH_Layer_master] folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user mne\n",
    "#!pip install --user seaborn\n",
    "#### pytorch and Cuda should be set up correctly on the Pytorch kernal or pytorch container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the code interactively in JupyterLab or by command line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.1 Use the following script: model parameters controlled by config/training_config.ini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.DoubleTensor'>\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.train_util import *\n",
    "from models.Deep_isith_EEG_model import *\n",
    "from models.LSTM_EEG_model import *\n",
    "import pandas as pd\n",
    "# read config file\n",
    "import configparser\n",
    "import argparse\n",
    "\n",
    "# preprocessing\n",
    "import mne\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "ttype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "labeltype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
    "print(ttype)\n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# training \n",
    "from torch import nn as nn\n",
    "from math import factorial\n",
    "import random\n",
    "import seaborn as sn\n",
    "import os \n",
    "from os.path import join\n",
    "import glob\n",
    "\n",
    "# validation\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, matthews_corrcoef,confusion_matrix,plot_roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- sith layer model parameters ------------------#\n",
    "# make sure this in_features matches the number of feutures in the EEG data\n",
    "# Use 3 layers per Per's advice,uses the k-opt code to get optimum  \n",
    "# taumax 50, 200, 800\n",
    "sith_params1 = {\"in_features\":32, \n",
    "                \"tau_min\":1, \"tau_max\":50, \n",
    "                \"k\":23, 'dt':1,\n",
    "                \"ntau\":10, 'g':0.0,  \n",
    "                \"ttype\":ttype, \n",
    "                \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "\n",
    "sith_params2 = {\"in_features\":sith_params1['hidden_size'], \n",
    "                \"tau_min\":1, \"tau_max\":200.0,  \n",
    "                \"k\":12, 'dt':1,\n",
    "                \"ntau\":10, 'g':0.0, \n",
    "                \"ttype\":ttype, \n",
    "                \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "sith_params3 = {\"in_features\":sith_params2['hidden_size'], \n",
    "            \"tau_min\":1, \"tau_max\":800.0,  \n",
    "            \"k\":7, 'dt':1,\n",
    "            \"ntau\":10, 'g':0.0, \n",
    "            \"ttype\":ttype, \n",
    "            \"hidden_size\":20, \"act_func\":nn.ReLU()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load Subject2 Data.\n",
      "Finished! 8 data are loaded and preprocessed\n",
      "torch.Size([1699, 32, 2000]) torch.Size([1699, 6, 2000])\n",
      "Starting to load Subject2 Data.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'grasp-and-lift-eeg-detection/validation/subj2_series10_events.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Senior Research Project\\Code\\MLCode\\SIF_Capstone\\example_training.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/example_training.ipynb#ch0000007?line=90'>91</a>\u001b[0m sub_idx \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/example_training.ipynb#ch0000007?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m file[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m_data\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m&\u001b[39m (file[\u001b[39m4\u001b[39m:sub_idx] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(subject_num)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/example_training.ipynb#ch0000007?line=92'>93</a>\u001b[0m     raw \u001b[39m=\u001b[39m creat_mne_raw_object(val_dir\u001b[39m+\u001b[39;49mfile,read_events\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/example_training.ipynb#ch0000007?line=93'>94</a>\u001b[0m     \u001b[39m# filter all channels\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/example_training.ipynb#ch0000007?line=94'>95</a>\u001b[0m     input_signal,target_signal \u001b[39m=\u001b[39m filter_standardization(raw,window_size \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/example_training.ipynb#ch0000007?line=95'>96</a>\u001b[0m                         l_freq \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,h_freq \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m)\n",
      "File \u001b[1;32mg:\\My Drive\\Senior Research Project\\Code\\MLCode\\SIF_Capstone\\src\\train_util.py:85\u001b[0m, in \u001b[0;36mcreat_mne_raw_object\u001b[1;34m(fname, read_events)\u001b[0m\n\u001b[0;32m     <a href='file:///g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/src/train_util.py?line=82'>83</a>\u001b[0m ev_fname \u001b[39m=\u001b[39m fname\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m_data\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m_events\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/src/train_util.py?line=83'>84</a>\u001b[0m \u001b[39m# read event file\u001b[39;00m\n\u001b[1;32m---> <a href='file:///g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/src/train_util.py?line=84'>85</a>\u001b[0m events \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(ev_fname)\n\u001b[0;32m     <a href='file:///g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/src/train_util.py?line=85'>86</a>\u001b[0m events_names \u001b[39m=\u001b[39m events\u001b[39m.\u001b[39mcolumns[\u001b[39m1\u001b[39m:]\n\u001b[0;32m     <a href='file:///g%3A/My%20Drive/Senior%20Research%20Project/Code/MLCode/SIF_Capstone/src/train_util.py?line=86'>87</a>\u001b[0m events_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(events[events_names])\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=570'>571</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=572'>573</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=581'>582</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=582'>583</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=583'>584</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=585'>586</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=478'>479</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=480'>481</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=481'>482</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=483'>484</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=484'>485</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=807'>808</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=808'>809</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=810'>811</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=1035'>1036</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=1036'>1037</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown engine: \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m (valid options are \u001b[39m\u001b[39m{\u001b[39;00mmapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=1037'>1038</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=1038'>1039</a>\u001b[0m \u001b[39m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/readers.py?line=1039'>1040</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mapping[engine](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=47'>48</a>\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[0;32m     <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=49'>50</a>\u001b[0m \u001b[39m# open handles\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=50'>51</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_handles(src, kwds)\n\u001b[0;32m     <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=51'>52</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=53'>54</a>\u001b[0m \u001b[39m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=217'>218</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_handles\u001b[39m(\u001b[39mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=218'>219</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=219'>220</a>\u001b[0m \u001b[39m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=220'>221</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=221'>222</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=222'>223</a>\u001b[0m         src,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=223'>224</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=224'>225</a>\u001b[0m         encoding\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=225'>226</a>\u001b[0m         compression\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=226'>227</a>\u001b[0m         memory_map\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=227'>228</a>\u001b[0m         storage_options\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=228'>229</a>\u001b[0m         errors\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/parsers/base_parser.py?line=229'>230</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=696'>697</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=697'>698</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=698'>699</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=699'>700</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=700'>701</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=701'>702</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=702'>703</a>\u001b[0m             handle,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=703'>704</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=704'>705</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=705'>706</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=706'>707</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=707'>708</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=708'>709</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=709'>710</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/io/common.py?line=710'>711</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'grasp-and-lift-eeg-detection/validation/subj2_series10_events.csv'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\"\"\"\n",
    "3.1\n",
    "General-purpose training script for Grasp-and-lift EEG data prediction and classification\n",
    "Currently support:\n",
    "1. A base model for LSTM (Rivanna GPU)\n",
    "2. Deep_isith module\n",
    "**Use Kernal PyTorch 1.4.0 Py3.7**  \n",
    "parts are from **Neural Network Example**(Authors: Brandon G. Jacques and Per B. Sederberg)\n",
    "\n",
    "Yibo Wang\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from src.train_util import *\n",
    "from models.Deep_isith_EEG_model import *\n",
    "from models.LSTM_EEG_model import *\n",
    "import pandas as pd\n",
    "# read config file\n",
    "import configparser\n",
    "import argparse\n",
    "\n",
    "# enable use of command line\n",
    "parser = argparse.ArgumentParser(description='Input config files')\n",
    "parser.add_argument('--config', default = 'config/training_config_Deep_isith.ini', type=str,\n",
    "                    help='an integer for the accumulator')\n",
    "opt, _ = parser.parse_known_args()\n",
    "\n",
    "# parser to read parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.sections()\n",
    "\n",
    "# parameters from config file\n",
    "results = []\n",
    "config.read(opt.config)\n",
    "dir = config['data']['directory']\n",
    "subject_num = int(config['data']['subject #'])\n",
    "kernel_size = int(config['training']['kernel_size'])# sliding window size to use\n",
    "step = int(config['training']['step']) #  --the step between each slice. means overlap between batches is 1- step \n",
    "modelName = config['training']['model']\n",
    "# num of epochs to train\n",
    "nepochs = int(config['training']['nepochs'])\n",
    "loss_func =  torch.nn.CrossEntropyLoss()\n",
    "batch_size = int(config['training']['batch_size']) # batch_size is a hyper parameter to tune \n",
    "lr = float(config['training']['lr'])\n",
    "\n",
    "# load data and do preprocessing\n",
    "train_x_list = []\n",
    "train_y_list = []\n",
    "train_dir = dir + 'train/'\n",
    "val_dir = dir + 'validation/'\n",
    "\n",
    "# load training data\n",
    "print(f\"Starting to load Subject{subject_num} Data.\")\n",
    "for file in os.listdir(train_dir):\n",
    "    sub_idx = file.find('_')\n",
    "    if file[:-4].endswith('_data') & (file[4:sub_idx] == str(subject_num)):\n",
    "        raw = creat_mne_raw_object(train_dir+file,read_events=True)\n",
    "        # filter all channels\n",
    "        input_signal,target_signal = filter_standardization(raw,window_size = 1000,\n",
    "                            l_freq = 0,h_freq = 30)\n",
    "\n",
    "        input_tensor = ttype(input_signal.reshape(1,1,input_signal.shape[0],-1))\n",
    "        target_tensor = labeltype(target_signal.reshape(6,-1)) # should be six channels\n",
    "        input_tensor = input_tensor.squeeze()\n",
    "        # patches data \n",
    "        patches_train = input_tensor.unfold(dimension = 1, size = kernel_size, step = step).permute(1,0,2)\n",
    "        patches_label = target_tensor.unfold(1, kernel_size, step).permute(1,0,2)\n",
    "        #print(patches_train.shape, patches_label.shape)\n",
    "\n",
    "        # append to a list\n",
    "        train_x_list.append(patches_train)\n",
    "        train_y_list.append(patches_label)  \n",
    "        \n",
    "if (not train_x_list) or (not train_y_list):\n",
    "    print(\"No specified data found!\")\n",
    "else:\n",
    "    print(\"Finished! {} data are loaded and preprocessed\".format(len(train_x_list)))\n",
    "\n",
    "# concatenate them\n",
    "train_x_t = torch.cat(train_x_list, dim=0)\n",
    "train_y_t = torch.cat(train_y_list, dim=0)\n",
    "print(train_x_t.shape, train_y_t.shape)\n",
    "\n",
    "val_x_list = []\n",
    "val_y_list = []\n",
    "# load validation data\n",
    "print(f\"Starting to load Subject{subject_num} Data.\")\n",
    "for file in os.listdir(val_dir):\n",
    "    sub_idx = file.find('_')\n",
    "    if file[:-4].endswith('_data') & (file[4:sub_idx] == str(subject_num)):\n",
    "        raw = creat_mne_raw_object(val_dir+file,read_events=True)\n",
    "        # filter all channels\n",
    "        input_signal,target_signal = filter_standardization(raw,window_size = 1000,\n",
    "                            l_freq = 0,h_freq = 30)\n",
    "\n",
    "        input_tensor = ttype(input_signal.reshape(1,1,input_signal.shape[0],-1))\n",
    "        target_tensor = labeltype(target_signal.reshape(6,-1)) # should be six channels\n",
    "        # for batch of 1 only squeeze the first dimension\n",
    "        input_tensor = input_tensor.squeeze(0)\n",
    "        target_tensor = target_tensor.unsqueeze(0)\n",
    "        ###########for validation do not patch data ###########\n",
    "        # patches data \n",
    "        #patches_train = input_tensor.unfold(dimension = 1, size = kernel_size, step = step).permute(1,0,2)\n",
    "        #patches_label = target_tensor.unfold(1, kernel_size, step).permute(1,0,2)\n",
    "        #print(patches_train.shape, patches_label.shape)\n",
    "        val_x_t = input_tensor\n",
    "        val_y_t = target_tensor\n",
    "        #test_y_t = torch.cat(train_y_list, dim=0)\n",
    "        print(val_x_t.shape, val_y_t.shape)\n",
    "        # append to a list\n",
    "        #val_x_list.append(patches_train)\n",
    "        #val_y_list.append(patches_label) \n",
    "        \n",
    "        \n",
    "# start training, iterate thorugh events\n",
    "for i in range(1,7): # There are six events 1 - 6\n",
    "    nClass = i - 1\n",
    "    train_y_t_nClass = train_y_t[:,nClass,:]\n",
    "    val_y_t_nClass = val_y_t[:,nClass,:]\n",
    "    # create dataloader class\n",
    "    train_loader,val_loader = load_data(train_x_t ,train_y_t_nClass,\n",
    "                                             val_x_t ,val_y_t_nClass,\n",
    "                                             batch_size = batch_size)\n",
    "\n",
    "    # match with modelsm currently model name has to be exact\n",
    "    if modelName == 'Deep_isith':\n",
    "        # make a copy of every dict don't want to change them\n",
    "        layer_params = [sith_params1.copy(), sith_params2.copy(),sith_params3.copy()]\n",
    "\n",
    "        #------------------ model configuration ------------------------#\n",
    "        # number of output feature should be 2 since we always train one at a time, so now 1+1\n",
    "        model = DeepSITH_Tracker(out=2,\n",
    "                                    layer_params=layer_params, \n",
    "                                    dropout=0.1).double()\n",
    "    elif modelName == 'LSTM':\n",
    "        hidden_size = 25 # try 256  later\n",
    "        # make sure this in_features matches the number of feutures in the EEG data\n",
    "        model = LSTM_EEG(in_features = 32, hidden_dim = hidden_size, \n",
    "                          out_feuture = 2,num_layers =3, dropout=0.1).double()\n",
    "    else:\n",
    "        print('Model name not recognized!')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    # map model to GPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    #------------------- start training ---------------------------#\n",
    "    perf = []\n",
    "    perf = train_model(model, ttype, train_loader, val_loader,\n",
    "                    optimizer, loss_func, epochs=nepochs)\n",
    "    results.append(perf)\n",
    "\n",
    "\n",
    "    if not os.path.exists('saved_NNs'):\n",
    "        os.makedirs('saved_NNs')\n",
    "    PATH = f'./saved_NNs/{modelName}_Subject{str(subject_num)}_numEvent{nClass}.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "# save results\n",
    "df = pd.DataFrame()\n",
    "event = ['HandStart','FirstDigitTouch','BothStartLoadPhase',\n",
    "            'LiftOff','Replace','BothReleased']\n",
    "for i in range(len(results)):\n",
    "    perf = results[i]\n",
    "    new_df = pd.DataFrame(perf)\n",
    "    new_df['event'] = event[i]\n",
    "    df = df.append(new_df)\n",
    "if not os.path.exists('csv'):\n",
    "    os.makedirs('csv')\n",
    "csv_name = f'./csv/{modelName}_Subject{str(subject_num)}.csv'\n",
    "df.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.2  \n",
    "        Use the --config file to specify training parameters.  \n",
    "        Can also be used to specify model used to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command line\n",
    "# Run in Jupyter notebook/LAb, can be very slow\n",
    "# !python src/train.py --config ./config/training_config_LSTM.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_all.py --config ./config/training_config_Deep_isith.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the train_all.py  \n",
    "### Submit SLURM job to train on Rivanna.  \n",
    "### need to first copy the pytorch-1.4.0-py37.sif container to Desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit SLURM job to train on Rivanna\n",
    "# need to first copy the pytorch-1.4.0-py37.sif container to Desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH -o deep_isith.out\n",
    "\n",
    "#SBATCH -e deep_isith.err\n",
    "\n",
    "#SBATCH -p gpu\n",
    "\n",
    "#SBATCH --gres=gpu:v100:1\n",
    "\n",
    "#SBATCH --mem=32000\n",
    "\n",
    "#SBATCH -t 36:00:00\n",
    "\n",
    "#SBATCH -A uva-dsi-msds\n",
    "\n",
    "module load singularity\n",
    "\n",
    "singularity run --nv /home/$USER/pytorch-1.4.0-py37.sif train_all.py --config ./config/training_config_Deep_isith.ini\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f96efbd20990c9b87154ff1e04974328ba5cd93cb6fdf3bf0ba6a60073362e50"
  },
  "kernelspec": {
   "display_name": "PyTorch 1.4.0 Py3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
